{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dutch primary school denomination classificator\n",
    " \n",
    "## Overview\n",
    "\n",
    "In the Netherland  children go to primary school on the next day after they turn 4 years old. And before that, when they are 2.5 or 3 year old, parents should choose a school for them. Ideally the best school for their baby. It's quite a big problem for non-native dutch parent, like me - I have no idea what is important,what should I think about, what should I look at in this process. For example, there are a lot of types of school, like 'Openbaar', 'Rooms-Katholiek', 'Protestants-Christelijk', etc. And for the person who never met this system before, it's not very clear which one should I choose and which one would fit my child. On the other hand, I want to make a desicion based on objective data like scores in final tests or how many pupils from the school were recommended to continue different 'level' of education in future, or for example 'quality' of students knowledge etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a result of all this thoughts I realized that I have a problem: I don't understand, do I need to choose a type of school together with other characteristics, or it can be explained by this characteristics. Then I can just choose other characteristics that I want for my childs school to have and they will just define the best type of school. In other words, is it possible to make a classifier which would identify whether school is Openbaar or Rooms-Katholiek or has other denomination, based on other characterrictics we have? \n",
    "I found and pool in the dataset the most important information I want to know about my childs future school, so now I want to know do I need to choose a denomination of a school (and spend time to investigate what each school denomination mean in Dutch culture, their comparison and so on)? Or I can just choose other characteristic (which looks more clear to me) and they will define a denomination of a school. So I will build a few classifiers based on different ML alghorithms, will try to choose the best of them and see if the best classifier works good enough to predict a denomination of a primary school.\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "Let's start with reading dataset from the file 'Score.csv' and only data from one year (for example, 2018):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "data_score = pd.read_csv(\"Score.csv\", error_bad_lines=False, sep=',', encoding = \"ISO-8859-1\") \n",
    "data_score = data_score[data_score['DATUM'] == 2018]\n",
    "print(data_score.shape)\n",
    "print(data_score.columns)\n",
    "data_score.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of variables here which define address of the school in different ways, so we need to choose one of them. I think we can leave 'GEMEENTENUMMER' column as the variable which explains location  and remove the rest of the the address columns and also 'BEVOEGD_GEZAG_NUMMER':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SCHOOL_ID', 'DATUM', 'INSTELLINGSNAAM_VESTIGING', 'POSTCODE_VESTIGING', 'PLAATSNAAM', 'GEMEENTENAAM', \n",
    "           'PROVINCIE', 'BEVOEGD_GEZAG_NUMMER', 'ZITPERC']\n",
    "print(data_score.shape)\n",
    "data_score.drop(columns, 1, inplace = True)\n",
    "print(data_score.shape)\n",
    "print(data_score.columns)\n",
    "data_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I would like to explore the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_score['DENOMINATIE_VESTIGING'].value_counts())\n",
    "plt.figure(figsize=(15,8))\n",
    "print(sns.countplot(x='DENOMINATIE_VESTIGING',data=data_score, \n",
    "                    order = data_score['DENOMINATIE_VESTIGING'].value_counts().index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset we got there are 3 categorical columns. Before start modelling, we need to convert all the categorical variables to numerical ones. Let's use ***LabelEncoder*** this time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_score['SOORT_PO'] = LabelEncoder().fit_transform(data_score['SOORT_PO'])\n",
    "\n",
    "data_score['DENOMINATIE_VESTIGING'] = LabelEncoder().fit_transform(data_score['DENOMINATIE_VESTIGING'])\n",
    "\n",
    "data_score['EXAMEN'] = LabelEncoder().fit_transform(data_score['EXAMEN'])\n",
    "data_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classification models\n",
    "\n",
    "Ley's try to build classification models using a few different ML alghorithms: Random Forest, SVM, KNN, XGBoosting. \n",
    "\n",
    "First of all, we need to split data to test and train subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "pred = data_score['DENOMINATIE_VESTIGING']\n",
    "\n",
    "data_score.drop('DENOMINATIE_VESTIGING', 1, inplace = True)\n",
    "\n",
    "random_state = 4004\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_score, pred, train_size=0.7, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state = random_state)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_test = rfc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_score = 100 * rfc.score(X_test, y_test)\n",
    "print(\"Random Forest's accuracy is: %3.2f\" % (rfc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "preds = knn.predict(X_test)\n",
    "pred_test = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score = 100 * knn.score(X_test, y_test)\n",
    "print(\"KNN's accuracy is: %3.2f\" % (knn_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "pred_test = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_score = 100 * svc.score(X_test, y_test)\n",
    "print(\"SVC's accuracy is: %3.2f\" % (svc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler_gnb = MaxAbsScaler()\n",
    "data = scaler_gnb.fit_transform(data_score)\n",
    "\n",
    "X_train_gnb, X_test_gnb, y_train_gnb, y_test_gnb = train_test_split(data, pred, train_size=0.7, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_gnb, y_train_gnb)\n",
    "pred_test = gnb.predict(X_test_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_score = 100 * gnb.score(X_test, y_test)\n",
    "print(\"Gaussian Naive Bayes accuracy is: %3.2f\" % (gnb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "pred_test = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score = (pred_test == y_test).sum() / len(pred_test)*100\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (xgb_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'Feature': data_score.columns,\n",
    "    'Importance': xgb.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances = importances.set_index('Feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'KNN', 'SVC', 'Naive Bayes', 'XGBoost'],\n",
    "    'Score': [rfc_score, knn_score, svc_score, gnb_score, xgb_score]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Model')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that none of the ML algorithm was able to build apropriate model, the best one shows accuracy = 53% which is almost the same as random classifier. It means that we can say anything about denomination of the school looking at this features, so it looks like I can't just choose this school parameters and don't think about denomination, to find the best school for my toddler, I also need to choose denomination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
