{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dutch primary school CET score\n",
    " \n",
    "## Overview\n",
    "\n",
    "In the Netherland  children go to primary school on the next day after they turn 4 years old. And before that parents should choose the best fitting school for their baby. I think that the best school for my baby should have a lot of charactheristic and also has an ability to give my baby a good knowlegde, so he could get a good score in the final exam to continue education in secondary school. I found that Dutch Ministry of education, culture and science open some of their data, so I collected them into dataset from https://duo.nl/open_onderwijsdata/databestanden/ and now I want to analyse what I have there. Ideally I also want to find is it possible to calcuate the quality of the education which school can give to students based on this data or we need some extra data to define this?\n",
    "One of the main factor that could define the quality of education is final exams score, I will analyse it first. First of all I want to know what does CET score depend on and how it defines by other factors. To solve this problem first I read the dataset from the file Score.csv and get data from the most last year we have(2018), will clean it, will make new feature which would means the level of the average CET score for each school. As a result I will try to build classifier for those CET score levels to be able predict \"how good\" the exam result will be depending on other parameters we have. I also will use a few algorithms to build a clafssifier and see which geaves us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Let's start with reading dataset from the file 'Score.csv' and only data from one year (for example, 2018):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6286, 34)\n",
      "Index(['SCHOOL_ID', 'DATUM', 'INSTELLINGSNAAM_VESTIGING', 'POSTCODE_VESTIGING',\n",
      "       'PLAATSNAAM', 'GEMEENTENUMMER', 'GEMEENTENAAM', 'PROVINCIE', 'SOORT_PO',\n",
      "       'DENOMINATIE_VESTIGING', 'EXAMEN', 'EXAMEN_AANTAL', 'EXAMEN_GEM',\n",
      "       'REKENEN_LAGER1F', 'REKENEN_1F', 'REKENEN_1S', 'REKENEN_2F',\n",
      "       'LV_LAGER1F', 'LV_1F', 'LV_2F', 'TV_LAGER1F', 'TV_1F', 'TV_2F', 'VSO',\n",
      "       'PRO', 'VMBO', 'VMBO_HAVO', 'HAVO', 'HAVO_VWO', 'VWO',\n",
      "       'ADVIES_NIET_MOGELIJK', 'TOTAAL_ADVIES', 'LJ8', 'ZIT'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHOOL_ID</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>INSTELLINGSNAAM_VESTIGING</th>\n",
       "      <th>POSTCODE_VESTIGING</th>\n",
       "      <th>PLAATSNAAM</th>\n",
       "      <th>GEMEENTENUMMER</th>\n",
       "      <th>GEMEENTENAAM</th>\n",
       "      <th>PROVINCIE</th>\n",
       "      <th>SOORT_PO</th>\n",
       "      <th>DENOMINATIE_VESTIGING</th>\n",
       "      <th>...</th>\n",
       "      <th>PRO</th>\n",
       "      <th>VMBO</th>\n",
       "      <th>VMBO_HAVO</th>\n",
       "      <th>HAVO</th>\n",
       "      <th>HAVO_VWO</th>\n",
       "      <th>VWO</th>\n",
       "      <th>ADVIES_NIET_MOGELIJK</th>\n",
       "      <th>TOTAAL_ADVIES</th>\n",
       "      <th>LJ8</th>\n",
       "      <th>ZIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>000AP_2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>De Schanskorf</td>\n",
       "      <td>2715BT</td>\n",
       "      <td>ZOETERMEER</td>\n",
       "      <td>637</td>\n",
       "      <td>Zoetermeer</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>Bo</td>\n",
       "      <td>Gereformeerd vrijgemaakt</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18740</th>\n",
       "      <td>000AR_2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>BS \"De Maasparel\"</td>\n",
       "      <td>6107AW</td>\n",
       "      <td>STEVENSWEERT</td>\n",
       "      <td>1641</td>\n",
       "      <td>Maasgouw</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>Bo</td>\n",
       "      <td>Rooms-Katholiek</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18741</th>\n",
       "      <td>000AV_2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>De Morgenster</td>\n",
       "      <td>3201CN</td>\n",
       "      <td>SPIJKENISSE</td>\n",
       "      <td>1930</td>\n",
       "      <td>Nissewaard</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>Bo</td>\n",
       "      <td>Gereformeerd vrijgemaakt</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18742</th>\n",
       "      <td>000AZ_2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>De Stapsteen</td>\n",
       "      <td>2971AR</td>\n",
       "      <td>BLESKENSGRAAF CA</td>\n",
       "      <td>1927</td>\n",
       "      <td>Molenwaard</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>Bo</td>\n",
       "      <td>Openbaar</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18743</th>\n",
       "      <td>000BB_2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Obs Letterwies</td>\n",
       "      <td>9944AR</td>\n",
       "      <td>NIEUWOLDA</td>\n",
       "      <td>1895</td>\n",
       "      <td>Oldambt</td>\n",
       "      <td>Groningen</td>\n",
       "      <td>Bo</td>\n",
       "      <td>Openbaar</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SCHOOL_ID  DATUM INSTELLINGSNAAM_VESTIGING POSTCODE_VESTIGING  \\\n",
       "18739  000AP_2018   2018             De Schanskorf             2715BT   \n",
       "18740  000AR_2018   2018         BS \"De Maasparel\"             6107AW   \n",
       "18741  000AV_2018   2018             De Morgenster             3201CN   \n",
       "18742  000AZ_2018   2018              De Stapsteen             2971AR   \n",
       "18743  000BB_2018   2018            Obs Letterwies             9944AR   \n",
       "\n",
       "             PLAATSNAAM  GEMEENTENUMMER GEMEENTENAAM     PROVINCIE SOORT_PO  \\\n",
       "18739        ZOETERMEER             637   Zoetermeer  Zuid-Holland       Bo   \n",
       "18740      STEVENSWEERT            1641     Maasgouw       Limburg       Bo   \n",
       "18741       SPIJKENISSE            1930   Nissewaard  Zuid-Holland       Bo   \n",
       "18742  BLESKENSGRAAF CA            1927   Molenwaard  Zuid-Holland       Bo   \n",
       "18743         NIEUWOLDA            1895      Oldambt     Groningen       Bo   \n",
       "\n",
       "          DENOMINATIE_VESTIGING  ... PRO  VMBO  VMBO_HAVO  HAVO  HAVO_VWO  \\\n",
       "18739  Gereformeerd vrijgemaakt  ...   0     0          2     4         0   \n",
       "18740           Rooms-Katholiek  ...   0     1          0     4         0   \n",
       "18741  Gereformeerd vrijgemaakt  ...   0     0          3     1         3   \n",
       "18742                  Openbaar  ...   2     1          5     3         0   \n",
       "18743                  Openbaar  ...   0     5          2     4         1   \n",
       "\n",
       "       VWO  ADVIES_NIET_MOGELIJK  TOTAAL_ADVIES  LJ8  ZIT  \n",
       "18739    3                     0             11   11    1  \n",
       "18740    9                     0             17   17    1  \n",
       "18741    2                     0             12   12    1  \n",
       "18742    3                     0             15   14    2  \n",
       "18743    2                     0             21   11    1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "data_score = pd.read_csv(\"./make_school_data/main/output/Score.csv\", error_bad_lines=False, sep=',', encoding = \"ISO-8859-1\") \n",
    "data_score = data_score[data_score['DATUM'] == 2018]\n",
    "print(data_score.shape)\n",
    "print(data_score.columns)\n",
    "data_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create new variable which would means how well students of particular school take the exam. We have a few exams chosen by schools, let's take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CET       3527\n",
       "IEP       1790\n",
       "ROUTE8     833\n",
       "DIA         83\n",
       "AMN         53\n",
       "Name: EXAMEN, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_score['EXAMEN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create new variable 'SCORE_TYPE' with values 'low' and 'high' depends on score and on the chosen exam, because average score is different for different exams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_score(row): \n",
    "    result = \"Low\"\n",
    "    exam_data = data_score[data_score['EXAMEN'] == row.EXAMEN]\n",
    "    if(row.EXAMEN_GEM < exam_data['EXAMEN_GEM'].median()):\n",
    "        result = \"Low\"\n",
    "    else:\n",
    "        result = \"High\"\n",
    "    return result\n",
    "\n",
    "data_score['SCORE_LEVEL'] =  data_score.apply(lambda row: get_type_score(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High    3146\n",
      "Low     3140\n",
      "Name: SCORE_LEVEL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_score['SCORE_LEVEL'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to remove unnecessary columns because some of them is higly correlated (like few columns which describe an address of school, we can leave only one of them) and some of them we just don't need (like 'SCHOOL_ID' or 'BEVOEGD_GEZAG_NUMMER') or they mean same thing as outcome (like score variable 'EXAMEN_GEM'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6286, 35)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['BEVOEGD_GEZAG_NUMMER' 'ZITPERC'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb88fe785985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m            'PROVINCIE', 'BEVOEGD_GEZAG_NUMMER', 'ZITPERC']\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4160\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4161\u001b[0m         \"\"\"\n\u001b[0;32m-> 4162\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4163\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4164\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3883\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3884\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3916\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3917\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3918\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3919\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5278\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5279\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['BEVOEGD_GEZAG_NUMMER' 'ZITPERC'] not found in axis\""
     ]
    }
   ],
   "source": [
    "columns = ['EXAMEN_GEM', 'SCHOOL_ID', 'DATUM', 'INSTELLINGSNAAM_VESTIGING', 'POSTCODE_VESTIGING', 'PLAATSNAAM', 'GEMEENTENAAM', \n",
    "           'PROVINCIE']#, 'BEVOEGD_GEZAG_NUMMER', 'ZITPERC'\n",
    "print(data_score.shape)\n",
    "data = data_score.drop(columns, 1)\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['SCORE_LEVEL'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "print(sns.countplot(x='SCORE_LEVEL',data=data, \n",
    "                    order = data['SCORE_LEVEL'].value_counts().index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome ('SCORE_LEVEL' column) values have almost the same amount of values, so we don't need to do anything with this sample (like oversampling or undersampling) and just continue with analysis. \n",
    "Let's encode categorical variables using LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data['SOORT_PO'] = LabelEncoder().fit_transform(data['SOORT_PO'])\n",
    "\n",
    "data['DENOMINATIE_VESTIGING'] = LabelEncoder().fit_transform(data['DENOMINATIE_VESTIGING'])\n",
    "\n",
    "data['EXAMEN'] = LabelEncoder().fit_transform(data['EXAMEN'])\n",
    "\n",
    "data['SCORE_LEVEL'] = LabelEncoder().fit_transform(data['SCORE_LEVEL'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start modelling, but first we need to normalize data (using MinMaxScaler) and split it on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import  plot_roc_curve\n",
    "\n",
    "random_state = 4004\n",
    "\n",
    "def split_data(data): \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, pred, train_size=0.7, test_size=0.3, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "pred = data['SCORE_LEVEL']\n",
    "data.drop('SCORE_LEVEL', 1, inplace = True)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = split_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models\n",
    "\n",
    "Let' start modelling. I will built classification model using a several ML algorithms: Random forest, K Nearest Neighbors, Support Vector Machine and XGBoost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state = random_state)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    pred_test = rfc.predict(X_test)\n",
    " \n",
    "    rfc_score = 100 * rfc.score(X_test, y_test)\n",
    "    print(\"Score is: %3.2f\" % (rfc_score))\n",
    "    \n",
    "    rfc_disp = plot_roc_curve(rfc, X_test, y_test)\n",
    "    return rfc, rfc_score, rfc_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "rfc, rfc_score, rfc_disp = random_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_test)\n",
    "    pred_test = knn.predict(X_test)\n",
    "    knn_score = 100 * knn.score(X_test, y_test)\n",
    "    print(\"Score is: %3.2f\" % (knn_score))\n",
    "    knn_disp = plot_roc_curve(knn, X_test, y_test)\n",
    "    return knn, knn_score, knn_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN\")\n",
    "knn, knn_score, knn_disp = knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(X_train, X_test, y_train, y_test):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    pred_test = svc.predict(X_test)\n",
    "    svc_score = 100 * svc.score(X_test, y_test)\n",
    "    print(\"Score is: %3.2f\" % (svc_score))\n",
    "    svc_disp = plot_roc_curve(svc, X_test, y_test)\n",
    "    return svc, svc_score, svc_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support Vector Machine\")\n",
    "svc, svc_score, svc_disp = svc(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(X_train, X_test, y_train, y_test):\n",
    "    xgb = XGBClassifier(n_estimators=100)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_test = xgb.predict(X_test)\n",
    "    xgb_score = (pred_test == y_test).sum() / len(pred_test)*100\n",
    "    print(\"Score is: %3.2f\" % (xgb_score))\n",
    "    xgb_disp = plot_roc_curve(xgb, X_test, y_test)\n",
    "    return xgb, xgb_score, xgb_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost\")\n",
    "xgb, xgb_score, xgb_disp = XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We made a few models, let's check which one gave more accurate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'KNN', 'SVC', 'XGBoost'],\n",
    "    'Score': [rfc_score, knn_score, svc_score, xgb_score]\n",
    "}).sort_values(by='Score', ascending=False).set_index('Model')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc plot\n",
    "ax = plt.gca()\n",
    "rfc_disp.plot(ax=ax, alpha=0.8)\n",
    "knn_disp.plot(ax=ax, alpha=0.8)\n",
    "svc_disp.plot(ax=ax, alpha=0.8)\n",
    "xgb_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that XGBoost and Random forest gave us almost the same result.\n",
    "Let's check now what factors was the most important:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'Feature': data.columns,\n",
    "    'Importance': xgb.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).set_index('Feature')\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the most important factors are amount of students who doesn't have enough math skills and those who has good language skills.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "As a result I can say that for prediction the level of CET exam XGBoost gives the better result. \n",
    "Also when I will choose the school with better then average quality of education, I need to take a look at number of student, who knows math not very well (and probably the smallest amount of such atudents, the better average CET score school would have)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
